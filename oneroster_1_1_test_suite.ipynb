{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhV1eoFWhd9Z"
      },
      "source": [
        "Copyright 2023 Google LLC.\n",
        "\n",
        "SPDX-License-Identifier: Apache-2.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# License"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hSmn9lPfhzTf"
      },
      "outputs": [],
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L752xU_BWtb9"
      },
      "source": [
        "# **OneRoster Integration Conformance Tests**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84x5E49Kc_sT"
      },
      "source": [
        "\n",
        "Self link: [Run in Colab](https://colab.research.google.com/github/googleworkspace/oneroster-integration-conformance-tests/blob/main/oneroster_1_1_test_suite.ipynb)![colab](https://cloud.google.com/ml-engine/images/colab-logo-32px.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZBBAK9RdsqL"
      },
      "source": [
        "# **Before you begin**\n",
        "\n",
        "While you are familiarizing yourself with the tests, it might be helpful to run each cell individually. However, when you are ready to submit results to Google, it is preferable to run all of the tests at once for a fully generated test report. Both Colab and Jupyter notebook allow you to run all cells.\n",
        "\n",
        "The report generated will include a report_card table that will hold the results of each test and a latency_report table that will hold the latency data for each API call. These are the tables that should be submitted to classroom-sis-external@google.com after all the tests are run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H755ZateMhW"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Before you run the tests, you will need to include the following in the “Enter credentials” code block:\n",
        "\n",
        "* Token url to retrieve OAuth 2 credentials\n",
        "* One Roster URL ending in \"/ims/oneroster/v1p1\"\n",
        "* Client ID\n",
        "* Client secret\n",
        "\n",
        "You will need an existing teacher email to test the \"GetAllTeachers with email filter\" code block:\n",
        "\n",
        "* A teacher email address"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Credentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqWB_jvr1ene"
      },
      "outputs": [],
      "source": [
        "token_url = input(\"Enter token URL: \")\n",
        "one_roster_url = input(\n",
        "    \"Enter OneRoster URL (ending in /ims/oneroster/v1p1): \")\n",
        "client_id = input(\"Enter your client id: \")\n",
        "client_secret = input(\"Enter your client secret: \")\n",
        "teacher_email_address = input(\"Enter a teacher email address: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "M1LlyWKDplcR"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta, timezone\n",
        "import json\n",
        "import uuid\n",
        "import requests\n",
        "from tabulate import tabulate\n",
        "from dataclasses import dataclass\n",
        "\n",
        "report_card = {}\n",
        "latency_report = {}\n",
        "test_headers = [\"Test\", \"Result\", \"Details\"]\n",
        "test_success = \"pass\"\n",
        "test_fail = \"FAIL\"\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    token_url: str\n",
        "    one_roster_url: str\n",
        "    client_id: str\n",
        "    client_secret: str\n",
        "    teacher_email_address: str\n",
        "    class_sourced_id: str = \"\"\n",
        "    teacher_sourced_id: str = \"\"\n",
        "    line_item_sourced_id: str = \"\"\n",
        "    result_sourced_id: str = \"\"\n",
        "    term_sourced_id: str = \"\"\n",
        "\n",
        "config = Config(\n",
        "    token_url = token_url,\n",
        "    one_roster_url = one_roster_url,\n",
        "    client_id = client_id,\n",
        "    client_secret = client_secret,\n",
        "    teacher_email_address = teacher_email_address,\n",
        ")\n",
        "\n",
        "@dataclass\n",
        "class TestResult:\n",
        "  name: str\n",
        "  status: str\n",
        "  details: str = \"\"\n",
        "\n",
        "  def data(self):\n",
        "    return (self.name, self.status, self.details)\n",
        "\n",
        "def check_status(response, expected_statuses: set[int]):\n",
        "    codes = \"/\".join([str(s) for s in expected_statuses])\n",
        "    test_name = f\"Status code {codes}\"\n",
        "    if response.status_code not in expected_statuses:\n",
        "        print(json.dumps(response.json(), indent=2))\n",
        "        return TestResult(test_name, status=test_fail, details=f\"{response.status_code} returned\").data()\n",
        "    details = f\"{response.status_code} returned\" if len(expected_statuses) > 1 else \"\"\n",
        "    return TestResult(name=test_name, status=test_success, details=details).data()\n",
        "\n",
        "def print_report(report_card, latency_report):\n",
        "    table_data = []\n",
        "    for test_name, results in report_card.items():\n",
        "        for result in results:\n",
        "            table_data.append((test_name, result[0], result[1], result[2] if len(result) > 2 else \"\"))\n",
        "\n",
        "    print(tabulate(table_data, headers=[\"Test Name\", \"Result\", \"Outcome\", \"Details\"]))\n",
        "    print(\"\\n\")\n",
        "    print(tabulate(latency_report.items(), headers=[\"Test Name\", \"Latency (ms)\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pjkucASInNa"
      },
      "source": [
        "# **Basic Grade Sync** [Required]\n",
        "\n",
        "For best experience, run all at once using ctrl+F9 or `run all` from runtime menu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Authorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6f21gL2UyPW1"
      },
      "outputs": [],
      "source": [
        "payload = {\n",
        "    \"grant_type\": \"client_credentials\",\n",
        "    \"scope\": \"https://purl.imsglobal.org/spec/or/v1p1/scope/roster.readonly \"\n",
        "             \"https://purl.imsglobal.org/spec/or/v1p1/scope/gradebook.readonly \"\n",
        "             \"https://purl.imsglobal.org/spec/or/v1p1/scope/gradebook.createput \"\n",
        "             \"https://purl.imsglobal.org/spec/or/v1p1/scope/gradebook.delete\"\n",
        "}\n",
        "headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
        "auth = requests.auth.HTTPBasicAuth(config.client_id, config.client_secret)\n",
        "\n",
        "response = requests.request(\n",
        "    \"POST\", config.token_url, auth=auth, headers=headers, data=payload\n",
        ")\n",
        "latency_report[\"Get OAuth Token\"] = response.elapsed.microseconds / 1000\n",
        "\n",
        "tests = [\n",
        "  check_status(response, {200})\n",
        "]\n",
        "\n",
        "if response.status_code == 200:\n",
        "  oauth_token = response.json()[\"access_token\"]\n",
        "  request_headers = {\"Authorization\": \"Bearer \" + oauth_token}\n",
        "  put_request_headers = {\n",
        "      \"Content-Type\": \"application/json\",\n",
        "      \"Authorization\": \"Bearer \" + oauth_token,\n",
        "  }\n",
        "\n",
        "  print(f\"OAuth token retrieved: {oauth_token}\\n\")\n",
        "\n",
        "print(tabulate(tests, headers=test_headers))\n",
        "\n",
        "report_card[\"Get OAuth Token\"] = tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Teachers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GetAllTeachers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4CwYUgoGz38r"
      },
      "outputs": [],
      "source": [
        "url = config.one_roster_url + \"/teachers\"\n",
        "\n",
        "response = requests.request(\"GET\", url, headers=request_headers)\n",
        "latency_report[\"GetAllTeachers\"] = response.elapsed.microseconds / 1000\n",
        "\n",
        "tests = [\n",
        "    check_status(response, {200})\n",
        "]\n",
        "\n",
        "print(tabulate(tests, headers=test_headers))\n",
        "\n",
        "report_card[\"GetAllTeachers\"] = tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GetAllTeachers with email filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YWEauNHpQxM5"
      },
      "outputs": [],
      "source": [
        "url = f\"{config.one_roster_url}/teachers?filter=email='{config.teacher_email_address}'&limit=10000\"\n",
        "\n",
        "response = requests.request(\"GET\", url, headers=request_headers)\n",
        "latency_report[\"GetAllTeachers w/ email filter\"] = (\n",
        "    response.elapsed.microseconds / 1000\n",
        ")\n",
        "data = response.json()\n",
        "\n",
        "tests = [\n",
        "  check_status(response, {200})\n",
        "]\n",
        "\n",
        "if response.status_code == 200:\n",
        "  test_result = TestResult(name=\"Validate teacher\", status=test_fail)\n",
        "  if len(data[\"users\"]) != 1:\n",
        "    test_result.details = f\"{len(data['users'])} teachers returned\"\n",
        "  elif data[\"users\"][0].keys() >= {\n",
        "      \"email\",\n",
        "      \"sourcedId\",\n",
        "  }:\n",
        "    test_result.status = test_success\n",
        "    teacher_sourced_id = data[\"users\"][0][\"sourcedId\"]\n",
        "  else:\n",
        "    test_result.details = \"email/sourcedId fields missing\"\n",
        "  tests.append(test_result.data())\n",
        "\n",
        "print(tabulate(tests, headers=test_headers))\n",
        "\n",
        "report_card[\"GetAllTeachers w/ email filter\"] = tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GetClassesForTeacher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nMNNS6GLuFnw"
      },
      "outputs": [],
      "source": [
        "url = f\"{config.one_roster_url}/teachers/{teacher_sourced_id}/classes?limit=10000&filter=status='active'\"\n",
        "\n",
        "response = requests.request(\"GET\", url, headers=request_headers)\n",
        "latency_report[\"GetClassesForTeacher\"] = response.elapsed.microseconds / 1000\n",
        "data = response.json()\n",
        "      \n",
        "tests = [\n",
        "  check_status(response, {200})\n",
        "]\n",
        "\n",
        "if response.status_code == 200:\n",
        "  config.class_sourced_id = data[\"classes\"][0][\"sourcedId\"]\n",
        "\n",
        "print(tabulate(tests, headers=test_headers))\n",
        "\n",
        "report_card[\"GetClassesForTeacher\"] = tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Students"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GetStudentsForClass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7gIwq3jNuF2p"
      },
      "outputs": [],
      "source": [
        "url = f\"{config.one_roster_url}/classes/{config.class_sourced_id}/students?limit=10000\"\n",
        "\n",
        "response = requests.request(\"GET\", url, headers=request_headers)\n",
        "latency_report[\"GetStudentsForClass\"] = response.elapsed.microseconds / 1000\n",
        "data = response.json()\n",
        "\n",
        "tests = [\n",
        "  check_status(response, {200})\n",
        "]\n",
        "\n",
        "if response.status_code == 200:\n",
        "  test_result = TestResult(name=\"Validate student\", status=test_fail)\n",
        "  if len(data[\"users\"]) == 0:\n",
        "    test_result.details = \"No students found\"\n",
        "  elif data[\"users\"][0].keys() >= {\"email\", \"sourcedId\"}:\n",
        "    student_sourced_id = data[\"users\"][0][\"sourcedId\"]\n",
        "    test_result.status = test_success\n",
        "  else:\n",
        "    test_result.details = \"email/sourcedId fields missing\"\n",
        "  tests.append(test_result.data())\n",
        "\n",
        "\n",
        "print(tabulate(tests, headers=test_headers))\n",
        "\n",
        "report_card[\"GetStudentsForClass\"] = tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LineItem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YjYY7llQuF9X"
      },
      "outputs": [],
      "source": [
        "line_item_sourced_id = str(uuid.uuid4())\n",
        "now = datetime.now(timezone.utc)\n",
        "assign_date = now.strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3] + \"Z\"\n",
        "due_date = (now + timedelta(minutes=1)).strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[\n",
        "    :-3\n",
        "] + \"Z\"\n",
        "\n",
        "url = f\"{config.one_roster_url}/lineItems/{line_item_sourced_id}\"\n",
        "\n",
        "payload = json.dumps(\n",
        "    {\n",
        "        \"lineItem\": {\n",
        "            \"sourcedId\": line_item_sourced_id,\n",
        "            \"title\": \"New test item\",\n",
        "            \"description\": \"Test Line Item\",\n",
        "            \"resultValueMin\": 0,\n",
        "            \"resultValueMax\": 100,\n",
        "            \"assignDate\": assign_date,\n",
        "            \"dueDate\": due_date,\n",
        "            \"class\": {\"sourcedId\": config.class_sourced_id},\n",
        "            \"category\": {\n",
        "                \"sourcedId\": \"84b742b5-739c-31d4-80f2-5613a61509cb-23\"\n",
        "            }\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "response = requests.request(\n",
        "    \"PUT\", url, headers=put_request_headers, data=payload\n",
        ")\n",
        "latency_report[\"PutLineItem Create\"] = response.elapsed.microseconds / 1000\n",
        "\n",
        "tests = [\n",
        "    check_status(response, {201})\n",
        "]\n",
        "if response.status_code == 201:\n",
        "    print(f\"Created line item with sourced ID {line_item_sourced_id}\\n\")\n",
        "\n",
        "print(tabulate(tests, headers=test_headers))\n",
        "\n",
        "report_card[\"PutLineItem Create\"] = tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "url = f\"{config.one_roster_url}/classes/{config.class_sourced_id}/lineItems?limit=10000\"\n",
        "\n",
        "response = requests.request(\"GET\", url, headers=request_headers)\n",
        "latency_report[\"GetLineItemsForClass\"] = response.elapsed.microseconds / 1000\n",
        "data = response.json()\n",
        "\n",
        "tests = [check_status(response, {200})]\n",
        "\n",
        "if response.status_code == 200:\n",
        "  if any(sd[\"sourcedId\"] == line_item_sourced_id for sd in data[\"lineItems\"]):\n",
        "    tests.append((\"Get created line item\", test_success))\n",
        "  else:\n",
        "    tests.append((\"Get created line item\", test_fail))\n",
        "\n",
        "\n",
        "print(tabulate(tests, headers=test_headers))\n",
        "\n",
        "report_card[\"GetLineItemsForClass\"] = tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Edit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9ilClVr3uGCw"
      },
      "outputs": [],
      "source": [
        "url = f\"{config.one_roster_url}/lineItems/{line_item_sourced_id}\"\n",
        "\n",
        "payload = json.dumps(\n",
        "    {\n",
        "        \"lineItem\": {\n",
        "            \"sourcedId\": line_item_sourced_id,\n",
        "            \"title\": (\n",
        "                \"[Amended]\"\n",
        "                \" Reallllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllly\"\n",
        "                \" Long Google Test Line Item Title\"\n",
        "            ),\n",
        "            \"description\": \"Test Line Item\",\n",
        "            \"resultValueMin\": 0,\n",
        "            \"resultValueMax\": 100,\n",
        "            \"assignDate\": assign_date,\n",
        "            \"dueDate\": due_date,\n",
        "            \"class\": {\"sourcedId\": config.class_sourced_id},\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "response = requests.request(\n",
        "    \"PUT\", url, headers=put_request_headers, data=payload\n",
        ")\n",
        "latency_report[\"PutLineItem Edit\"] = response.elapsed.microseconds / 1000\n",
        "\n",
        "tests = [check_status(response, {200, 201})]\n",
        "\n",
        "print(tabulate(tests, headers=test_headers))\n",
        "\n",
        "if response.status_code == 201:\n",
        "  print(\"\\nINFO: Modifying existing resource should return status code 200\")\n",
        "\n",
        "report_card[\"PutLineItem Edit\"] = tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get (Assignment Title Limit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SG6wXqBduGEl"
      },
      "outputs": [],
      "source": [
        "url = f\"{config.one_roster_url}/classes/{config.class_sourced_id}/lineItems?limit=10000\"\n",
        "\n",
        "response = requests.request(\"GET\", url, headers=request_headers)\n",
        "latency_report[\"GetLineItemsForClass: Assignment Title Limit\"] = (\n",
        "    response.elapsed.microseconds / 1000\n",
        ")\n",
        "data = response.json()\n",
        "\n",
        "tests = [check_status(response, {200})]\n",
        "if response.status_code == 200:\n",
        "  for d in data[\"lineItems\"]:\n",
        "    if d[\"sourcedId\"] == line_item_sourced_id:\n",
        "      if d:\n",
        "        tests.append((\"Line item title limit\", test_success, len(d[\"title\"])))\n",
        "      else:\n",
        "        tests.append((\"Line item exists\", test_fail))\n",
        "        print(json.dumps(d, indent=2))\n",
        "      break\n",
        "\n",
        "print(tabulate(tests, headers=test_headers))\n",
        "\n",
        "report_card[\"Assignment Title Limit\"] = tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Fysf1yO7uGGe"
      },
      "outputs": [],
      "source": [
        "result_sourced_id = str(uuid.uuid4())\n",
        "\n",
        "url = f\"{config.one_roster_url}/results/{result_sourced_id}\"\n",
        "\n",
        "payload = json.dumps(\n",
        "    {\n",
        "        \"result\": {\n",
        "            \"sourcedId\": result_sourced_id,\n",
        "            \"score\": 80,\n",
        "            \"comment\": \"\",\n",
        "            \"scoreStatus\": \"fully graded\",\n",
        "            \"scoreDate\": assign_date,\n",
        "            \"lineItem\": {\"sourcedId\": line_item_sourced_id},\n",
        "            \"student\": {\"sourcedId\": student_sourced_id},\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "response = requests.request(\n",
        "    \"PUT\", url, headers=put_request_headers, data=payload\n",
        ")\n",
        "latency_report[\"PutResult Create\"] = response.elapsed.microseconds / 1000\n",
        "\n",
        "tests = [check_status(response, {200, 201})]\n",
        "if response.status_code in {200, 201}:\n",
        "  print(f\"Created result with sourced ID {result_sourced_id}\\n\")\n",
        "\n",
        "print(tabulate(tests, headers=test_headers))\n",
        "\n",
        "report_card[\"PutResult Create\"] = tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UTXoVNm1uGIr"
      },
      "outputs": [],
      "source": [
        "url = f\"{config.one_roster_url}/classes/{config.class_sourced_id}/lineItems/{line_item_sourced_id}/results?limit=10000\"\n",
        "\n",
        "response = requests.request(\"GET\", url, headers=request_headers)\n",
        "latency_report[\"GetResultsForLineItem\"] = response.elapsed.microseconds / 1000\n",
        "data = response.json()\n",
        "\n",
        "tests = [check_status(response, {200})]\n",
        "if response.status_code == 200:\n",
        "  if any(sd[\"sourcedId\"] == result_sourced_id for sd in data[\"results\"]):\n",
        "    tests.append((\"Get created result\", test_success))\n",
        "  else:\n",
        "    tests.append((\"Get created result\", test_fail))\n",
        "\n",
        "print(tabulate(tests, headers=test_headers))\n",
        "\n",
        "report_card[\"GetResultsForLineItem\"] = tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Edit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6wnqnPW2uGOx"
      },
      "outputs": [],
      "source": [
        "url = f\"{config.one_roster_url}/results/{result_sourced_id}\"\n",
        "\n",
        "payload = json.dumps(\n",
        "    {\n",
        "        \"result\": {\n",
        "            \"sourcedId\": result_sourced_id,\n",
        "            \"score\": 300,\n",
        "            \"comment\": \"\",\n",
        "            \"scoreStatus\": \"fully graded\",\n",
        "            \"scoreDate\": assign_date,\n",
        "            \"lineItem\": {\"sourcedId\": line_item_sourced_id},\n",
        "            \"student\": {\"sourcedId\": student_sourced_id},\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "response = requests.request(\n",
        "    \"PUT\", url, headers=put_request_headers, data=payload\n",
        ")\n",
        "latency_report[\"PutResult Edit\"] = response.elapsed.microseconds / 1000\n",
        "\n",
        "tests = [check_status(response, {200, 201})]\n",
        "\n",
        "print(tabulate(tests, headers=test_headers))\n",
        "\n",
        "if response.status_code == 201:\n",
        "  print(\"\\nINFO: Modifying existing resource should return status code 200\")\n",
        "\n",
        "report_card[\"PutResult Edit\"] = tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get (Extra Credit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pz9_KzOrjRsS"
      },
      "outputs": [],
      "source": [
        "url = f\"{config.one_roster_url}/classes/{config.class_sourced_id}/lineItems/{line_item_sourced_id}/results?limit=10000\"\n",
        "\n",
        "response = requests.request(\"GET\", url, headers=request_headers)\n",
        "latency_report[\"GetResultsForLineItem Extra Credit\"] = (\n",
        "    response.elapsed.microseconds / 1000\n",
        ")\n",
        "data = response.json()\n",
        "\n",
        "tests = [check_status(response, {200})]\n",
        "\n",
        "for r in data[\"results\"]:\n",
        "  if r[\"sourcedId\"] == result_sourced_id:\n",
        "    if r[\"score\"] == 300:\n",
        "      tests.append((\"Result extra credit OK\", test_success))\n",
        "    else:\n",
        "      tests.append((\"Result extra credit OK\", test_fail))\n",
        "      print(json.dumps(r, indent=2))\n",
        "    break\n",
        "\n",
        "\n",
        "print(tabulate(tests, headers=test_headers))\n",
        "\n",
        "report_card[\"Result Extra Credit\"] = tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create (Exempt state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result_sourced_id = str(uuid.uuid4())\n",
        "\n",
        "url = f\"{config.one_roster_url}/results/{result_sourced_id}\"\n",
        "\n",
        "payload = json.dumps(\n",
        "    {\n",
        "        \"result\": {\n",
        "            \"sourcedId\": result_sourced_id,\n",
        "            \"score\": 80,\n",
        "            \"comment\": \"\",\n",
        "            \"scoreStatus\": \"exempt\",\n",
        "            \"scoreDate\": assign_date,\n",
        "            \"lineItem\": {\"sourcedId\": line_item_sourced_id},\n",
        "            \"student\": {\"sourcedId\": student_sourced_id},\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "response = requests.request(\n",
        "    \"PUT\", url, headers=put_request_headers, data=payload\n",
        ")\n",
        "latency_report[\"PutResult Create Exempt\"] = response.elapsed.microseconds / 1000\n",
        "\n",
        "tests = [check_status(response, {200, 201})]\n",
        "if response.status_code in {200, 201}:\n",
        "  print(f\"Created result with sourced ID {result_sourced_id}\\n\")\n",
        "\n",
        "print(tabulate(tests, headers=test_headers))\n",
        "\n",
        "report_card[\"PutResult Create Exempt\"] = tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get (Exempt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "url = f\"{config.one_roster_url}/classes/{config.class_sourced_id}/lineItems/{line_item_sourced_id}/results?limit=10000\"\n",
        "\n",
        "response = requests.request(\"GET\", url, headers=request_headers)\n",
        "latency_report[\"GetResultsForLineItem Exempt\"] = response.elapsed.microseconds / 1000\n",
        "data = response.json()\n",
        "print(json.dumps(data, indent=2))\n",
        "tests = [check_status(response, {200})]\n",
        "if response.status_code == 200:\n",
        "  result = next(filter(lambda sd: sd[\"sourcedId\"] == result_sourced_id, data[\"results\"]), None)\n",
        "  if result and result[\"scoreStatus\"] == \"exempt\":\n",
        "    tests.append((\"Returned excused state\", test_success))\n",
        "  else:\n",
        "    tests.append((\"Returned excused state\", test_fail))\n",
        "\n",
        "print(tabulate(tests, headers=test_headers))\n",
        "\n",
        "report_card[\"GetResultsForLineItem Exempt\"] = tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Delete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dB4KEXAGjRuv"
      },
      "outputs": [],
      "source": [
        "url = f\"{config.one_roster_url}/results/{result_sourced_id}\"\n",
        "\n",
        "response = requests.request(\"DELETE\", url, headers=request_headers)\n",
        "\n",
        "tests = [check_status(response, {200, 204})]\n",
        "if response.status_code == 200 or response.status_code == 204:\n",
        "  latency_report[\"DeleteResult\"] = response.elapsed.microseconds / 1000\n",
        "\n",
        "\n",
        "print(tabulate(tests, headers=test_headers))\n",
        "\n",
        "report_card[\"DeleteResult\"] = tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get (Deleted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "j9kl10ivjRxJ"
      },
      "outputs": [],
      "source": [
        "url = f\"{config.one_roster_url}/classes/{config.class_sourced_id}/lineItems/{line_item_sourced_id}/results?limit=10000\"\n",
        "\n",
        "response = requests.request(\"GET\", url, headers=request_headers)\n",
        "latency_report[\"GetResultsForLineItem (Deleted)\"] = (\n",
        "    response.elapsed.microseconds / 1000\n",
        ")\n",
        "data = response.json()\n",
        "\n",
        "tests = []\n",
        "if not any(sd[\"sourcedId\"] == result_sourced_id for sd in data[\"results\"]):\n",
        "  tests.append((\"Result deleted\", test_success))\n",
        "else:\n",
        "  tests.append((\"Result deleted\", test_fail))\n",
        "  print(json.dumps(data, indent=2))\n",
        "\n",
        "\n",
        "print(tabulate(tests, headers=test_headers))\n",
        "\n",
        "report_card[\"GetResultsForLineItem (Deleted)\"] = tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LineItem (Optional / Cleanup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Delete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QkwC8jDHnmpN"
      },
      "outputs": [],
      "source": [
        "url = f\"{config.one_roster_url}/lineItems/{line_item_sourced_id}\"\n",
        "\n",
        "response = requests.request(\"DELETE\", url, headers=request_headers)\n",
        "latency_report[\"DeleteLineItem\"] = response.elapsed.microseconds / 1000\n",
        "\n",
        "tests = [check_status(response, {200, 204})]\n",
        "\n",
        "print(tabulate(tests, headers=test_headers))\n",
        "\n",
        "report_card[\"DeleteLineItem\"] = tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get (Deleted LineItem)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZaXlwowfnmsA"
      },
      "outputs": [],
      "source": [
        "url = f\"{config.one_roster_url}/classes/{config.class_sourced_id}/lineItems?limit=10000\"\n",
        "\n",
        "response = requests.request(\"GET\", url, headers=request_headers)\n",
        "latency_report[\"GetLineItemsForClass (Deleted)\"] = (\n",
        "    response.elapsed.microseconds / 1000\n",
        ")\n",
        "data = response.json()\n",
        "\n",
        "tests = []\n",
        "if not any(sd[\"sourcedId\"] == line_item_sourced_id for sd in data[\"lineItems\"]):\n",
        "  tests.append((\"Line item deleted\", test_success))\n",
        "else:\n",
        "  tests.append((\"Line item deleted\", test_fail))\n",
        "  print(json.dumps(data, indent=2))\n",
        "\n",
        "\n",
        "print(tabulate(tests, headers=test_headers))\n",
        "\n",
        "report_card[\"GetLineItemsForClass (Deleted)\"] = tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Print Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yqhfL2FT7DBw"
      },
      "outputs": [],
      "source": [
        "print_report(report_card, latency_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIJUWuzWpGUh"
      },
      "source": [
        "# **Grading Categories** [Required]\n",
        "\n",
        "*Only one GET categories endpoint is needed. Please comment out any that are not implemented in order for `run all` to execute successfully.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GetAllCategories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3uE9MR--pVpI"
      },
      "outputs": [],
      "source": [
        "url = f\"{config.one_roster_url}/categories?limit=10000\"\n",
        "\n",
        "response = requests.request(\"GET\", url, headers=request_headers, data=payload)\n",
        "latency_report[\"GetAllCategories\"] = response.elapsed.microseconds / 1000\n",
        "data = response.json()\n",
        "\n",
        "tests = [check_status(response, {200})]\n",
        "if response.status_code == 200:\n",
        "  category_sourced_id = data[\"categories\"][0][\"sourcedId\"]\n",
        "\n",
        "\n",
        "print(tabulate(tests, headers=test_headers))\n",
        "\n",
        "report_card[\"GetAllCategories\"] = tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GetCategoriesForClass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ejuc9db3uIjE"
      },
      "outputs": [],
      "source": [
        "url = f\"{config.one_roster_url}/classes/{config.class_sourced_id}/categories?limit=10000\"\n",
        "\n",
        "response = requests.request(\"GET\", url, headers=request_headers, data=payload)\n",
        "latency_report[\"GetCategoriesForClass\"] = response.elapsed.microseconds / 1000\n",
        "data = response.json()\n",
        "\n",
        "tests = [check_status(response, {200})]\n",
        "if response.status_code == 200:\n",
        "  category_sourced_id = data[\"categories\"][0][\"sourcedId\"]\n",
        "\n",
        "\n",
        "print(tabulate(tests, headers=test_headers))\n",
        "\n",
        "report_card[\"GetCategoriesForClass\"] = tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PutLineItem w/ category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "poJ4jK3GuIlm"
      },
      "outputs": [],
      "source": [
        "line_item_sourced_id = str(uuid.uuid4())\n",
        "\n",
        "url = f\"{config.one_roster_url}/lineItems/{line_item_sourced_id}\"\n",
        "\n",
        "payload = json.dumps(\n",
        "    {\n",
        "        \"lineItem\": {\n",
        "            \"sourcedId\": line_item_sourced_id,\n",
        "            \"title\": \"Google Test Line Item Title\",\n",
        "            \"description\": \"Test Line Item\",\n",
        "            \"resultValueMin\": 0,\n",
        "            \"resultValueMax\": 100,\n",
        "            \"assignDate\": assign_date,\n",
        "            \"dueDate\": due_date,\n",
        "            \"category\": {\"sourcedId\": category_sourced_id},\n",
        "            \"class\": {\"sourcedId\": config.class_sourced_id},\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "response = requests.request(\n",
        "    \"PUT\", url, headers=put_request_headers, data=payload\n",
        ")\n",
        "latency_report[\"PutLineItem w/ Category\"] = response.elapsed.microseconds / 1000\n",
        "\n",
        "tests = [check_status(response, {201})]\n",
        "if response.status_code == 201:\n",
        "  print(f\"Created line item with sourced ID {line_item_sourced_id}\\n\")\n",
        "\n",
        "\n",
        "print(tabulate(tests, headers=test_headers))\n",
        "\n",
        "report_card[\"PutLineItem w/ Category\"] = tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GetLineItemsForClass (Category exists)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6xjPKc2GuIog"
      },
      "outputs": [],
      "source": [
        "url = f\"{config.one_roster_url}/classes/{config.class_sourced_id}/lineItems?limit=10000\"\n",
        "\n",
        "response = requests.request(\"GET\", url, headers=request_headers)\n",
        "latency_report[\"GetLineItemsForClass (Category exists)\"] = (\n",
        "    response.elapsed.microseconds / 1000\n",
        ")\n",
        "data = response.json()\n",
        "\n",
        "tests = []\n",
        "\n",
        "for d in data[\"lineItems\"]:\n",
        "  if d[\"sourcedId\"] == line_item_sourced_id:\n",
        "    if d and d[\"category\"][\"sourcedId\"] == category_sourced_id:\n",
        "      tests.append((\"Line item created with category\", test_success))\n",
        "    else:\n",
        "      tests.append((\"Line item created with category\", test_fail))\n",
        "      print(json.dumps(d, indent=2))\n",
        "    break\n",
        "\n",
        "\n",
        "print(tabulate(tests, headers=test_headers))\n",
        "\n",
        "report_card[\"GetLineItemsForClass (Category exists)\"] = tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DeleteLineItem (Optional / Cleanup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YEPRphAFuIq5"
      },
      "outputs": [],
      "source": [
        "url = f\"{config.one_roster_url}/lineItems/{line_item_sourced_id}\"\n",
        "\n",
        "response = requests.request(\"DELETE\", url, headers=request_headers)\n",
        "\n",
        "tests = [check_status(response, {200, 204})]\n",
        "\n",
        "\n",
        "print(tabulate(tests, headers=test_headers))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Print Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2Hv5Lqmy_4IO"
      },
      "outputs": [],
      "source": [
        "print_report(report_card, latency_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlLBnm8wxjQv"
      },
      "source": [
        "# **Grading Periods** [Required]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GetAllClasses w/ filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eB3ZbX8ruI5p"
      },
      "outputs": [],
      "source": [
        "url = f\"{config.one_roster_url}/classes?filter=sourcedId='{config.class_sourced_id}'&limit=10000\"\n",
        "\n",
        "response = requests.request(\"GET\", url, headers=request_headers)\n",
        "latency_report[\"GetAllClasses w/ filter\"] = response.elapsed.microseconds / 1000\n",
        "data = response.json()\n",
        "\n",
        "tests = [check_status(response, {200})]\n",
        "if response.status_code == 200:\n",
        "  if len(data[\"classes\"]) == 1 and data[\"classes\"][0].keys() >= {\n",
        "      \"terms\",\n",
        "      \"sourcedId\",\n",
        "  }:\n",
        "    term_sourced_id = data[\"classes\"][0][\"terms\"][0][\"sourcedId\"]\n",
        "    tests.append((\"Validate class\", test_success))\n",
        "  else:\n",
        "    tests.append((\"Validate class\", test_fail))\n",
        "\n",
        "\n",
        "print(tabulate(tests, headers=test_headers))\n",
        "\n",
        "report_card[\"GetAllClasses w/ filter\"] = tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GetGradingPeriodsForTerm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Q8rEd1tH2H_Y"
      },
      "outputs": [],
      "source": [
        "url = f\"{config.one_roster_url}/terms/{term_sourced_id}/gradingPeriods?limit=10000\"\n",
        "\n",
        "response = requests.request(\"GET\", url, headers=request_headers)\n",
        "latency_report[\"GetGradingPeriodsForTerm\"] = (\n",
        "    response.elapsed.microseconds / 1000\n",
        ")\n",
        "data = response.json()\n",
        "\n",
        "tests = [check_status(response, {200})]\n",
        "if response.status_code == 200:\n",
        "  if data[\"academicSessions\"][0].keys() >= {\n",
        "      \"sourcedId\",\n",
        "      \"title\",\n",
        "      \"startDate\",\n",
        "      \"endDate\",\n",
        "      \"schoolYear\",\n",
        "  }:\n",
        "    tests.append((\"Validate grading period\", test_success))\n",
        "  else:\n",
        "    tests.append((\"Validate grading period\", test_fail))\n",
        "\n",
        "  tests.append((\"Academic sessions all grading period types\", test_success))\n",
        "  for d in data[\"academicSessions\"]:\n",
        "    if d[\"type\"] != \"gradingPeriod\":\n",
        "      tests.append((\"Academic sessions all grading period types\", test_fail))\n",
        "      print(json.dumps(d, indent=2))\n",
        "      break\n",
        "\n",
        "\n",
        "print(tabulate(tests, headers=test_headers))\n",
        "\n",
        "report_card[\"GetGradingPeriodsForTerm\"] = tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Print Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SLe76ajf__N5"
      },
      "outputs": [],
      "source": [
        "print_report(report_card, latency_report)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
